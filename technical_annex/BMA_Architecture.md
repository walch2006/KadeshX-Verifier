# 技术解密：BMA (双模态记忆架构)

## 1. 核心挑战：记忆-即时性悖论
传统大模型在处理超长上下文时面临两个极端：
- **全文回顾式**：处理极慢，VRAM 占用呈指数级增长。
- **摘要检索式**：丢失细节，无法维持长期的逻辑连贯性。

## 2. 解决方案：林华书-灵曦 BMA 架构
BMA 模仿人类大脑的二元结构，将 Obsidian 作为“体外大脑”：

### 2.1 视网膜/工作记忆 (Active Context)
- **载体**：大模型当前窗口。
- **职能**：捕捉当前对话的瞬时意图。
- **策略**：只保留最近的 5-10 个逻辑原子。

### 2.2 大脑皮层/长期记忆 (Structured Archive)
- **载体**：Obsidian 本地库。
- **职能**：存储经过 LCS 坍缩后的逻辑不变量。
- **结构**：卢曼式原子卡片，通过 `lingxi_zettel_engine.py` 自动化管理。

## 3. 为什么它比传统模型更强？
- **无限容量**：受限于硬盘而非模型参数。
- **可审计性**：用户可以打开 Obsidian 文件夹，查看并修改每一个逻辑原子。
- **离线生存**：逻辑主权归于本地，不依赖云端 API。

---
*欲获取详细的 LCS 算法描述，请关注 LOGIC_HASH 的后续验证。*
